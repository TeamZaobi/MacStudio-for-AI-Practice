# Mac Studio LLM 实验平台操作规则 (.windsurf_rules.md)

本文档旨在规范在 Mac Studio 本地 LLM 实验平台上的操作，确保环境一致性、资源可管理性和实验可复现性。

## 一、 环境管理 (Environment Management)

1.  **强制使用 Conda:** **必须** 使用 `Miniforge` 或 `Mambaforge` 作为 Python 环境和依赖管理的基础。
2.  **严格隔离:** 为**每一个独立实验或核心工具链组合**（如 Ollama 测试、MLX 实验、LangChain Agent 开发等）创建**专门的 Conda 环境**。
    ```bash
    # 示例：创建一个名为 'my_mlx_exp' 的环境
    conda create -n my_mlx_exp python=3.10 -y
    ```
3.  **先激活再操作:** 在进行任何安装 (`pip install`, `conda install`)、编码或运行脚本**之前**，**必须**在终端中激活对应的 Conda 环境。
    ```bash
    conda activate my_mlx_exp
    ```
4.  **验证环境:** 使用 `which python` 和 `pip list` 或 `conda list` 确认当前使用的是正确的环境和依赖。
5.  **依赖记录:** 在每个项目或实验环境稳定后，**务必**使用以下命令之一记录依赖，并将生成的文件纳入 Git 管理。
    ```bash
    # Pip 环境
    pip freeze > requirements.txt
    # Conda 环境
    conda env export > environment.yml
    ```

## 二、 模型管理 (Model Management)

1.  **结构化存储:** 认识到模型来源多样、格式繁多 (GGUF, PyTorch/HF, MLX...)、大小不一，**必须**建立**清晰、统一的模型存储目录结构**。
    *   **建议手动管理目录:** 在用户主目录下创建一个中心模型存储位置，例如 `~/llm_models`。
    *   **按格式/模型族组织:** 在中心目录下，按模型格式或主要框架组织子目录，再按模型家族细分。示例结构：
        ```text
~/llm_models/
├── gguf/                  # GGUF 格式 (用于 Llama.cpp, Ollama 等)
│   ├── Llama3/
│   │   ├── Llama3-8B-Instruct-Q4_K_M.gguf
│   │   └── Llama3-70B-Instruct-Q5_K_S.gguf
│   └── Mistral/
│       ├── Mistral-7B-Instruct-v0.2-Q4_K_M.gguf
│       └── Mistral-8x7B-Instruct-v0.1-Q5_K_M.gguf
├── mlx_format/            # MLX 原生格式 (若需手动管理)
│   └── Mistral-7B-Instruct-v0.2-mlx/
│       └── ... (模型文件)
└── other_formats/         # 其他需要手动管理的格式
    └── ...
```
    *   **了解自动缓存:** 注意 Hugging Face Transformers/Diffusers 等库默认使用 `~/.cache/huggingface/hub` 作为缓存。Ollama 默认使用 `~/.ollama/models` 存储其拉取的模型。除非有特殊需求，通常无需手动干预这些自动缓存目录。
2.  **命名规范:** 对下载的、需要手动管理的模型文件或文件夹采用**一致的命名规范**，方便识别关键信息。
    *   **建议格式:** `<ModelFamily>-<Size>-<Variant>-<Quantization>.<Format>`
    *   **示例:**
        *   `Llama3-8B-Instruct-Q4_K_M.gguf`
        *   `Mistral-7B-v0.1-fp16.safetensors` (若手动下载 HF 模型)
        *   `Phi3-3.8B-Mini-Instruct-4k-Q5_K_M.gguf`
3.  **利用量化:** 根据实验需求和硬件限制，合理选择和使用**模型量化**版本 (如 GGUF 的 Q4/Q5/Q8 量化)，以平衡性能和资源占用。务必在文件名中体现量化级别。
4.  **存储选型:** 优先使用 Mac Studio 的**高速内置 SSD** 或**高速雷雳 (Thunderbolt) 外接 SSD** 存储模型文件，尤其是大型模型。考虑将中心模型目录 (`~/llm_models`) 放在速度最快的驱动器上。

## 三、 开发与实验流程 (Development & Experiment Workflow)

1.  **远程开发:** 推荐使用 **MacBook 上的 Cursor** 编辑器，通过 **Remote-SSH** 扩展连接到 Mac Studio 进行开发。确保 Mac Studio 已开启**远程登录** (`系统设置` > `通用` > `共享`)。
2.  **网络连接:** 使用 **Tailscale** 建立稳定、安全的远程访问网络。
3.  **资源监控:** 在运行模型推理、微调或复杂 Agent 逻辑时，**必须始终**打开 `asitop` (推荐) 或 `htop` 等工具，实时监控 Mac Studio 的 CPU、GPU (ANE/GPU Cores)、内存使用情况和温度。

## 四、 版本控制 (Version Control)

1.  **强制使用 Git:** 所有实验代码、项目配置文件、依赖记录文件 (`requirements.txt`, `environment.yml`)、重要的笔记或文档 (`.md`) **必须**使用 **Git** 进行版本管理。
2.  **及时提交:** 遵循良好的 Git 实践，进行原子化提交，并编写清晰的 Commit Message。

## 五、 实验跟踪 (Experiment Tracking)

1.  **推荐工具:** 对于需要系统化追踪参数、指标、模型版本和结果的可复现实验，强烈推荐使用实验管理工具，如 **MLflow** (本地/私有部署) 或 **Weights & Biases (WandB)** (云平台)。

## 六、 基础软件安装 (Base Software Installation)

1.  **包管理器:** 使用 **Homebrew (`brew`)** 安装和管理基础命令行工具 (如 `ollama`, `htop`, `git` 等)。
