# PRD: Mac Studio M3 Ultra 大模型实验平台

## 1. 产品概述
### 1.1 文档标题和版本
- PRD: Mac Studio M3 Ultra 大模型实验平台
- 版本: 1.0

### 1.2 产品摘要
本产品需求文档描述了一个基于Mac Studio M3 Ultra的大型语言模型实验平台的设计和实现方案。该平台旨在提供一个灵活、强大且易于管理的环境，用于探索、测试和评估最新的大型语言模型（包括671B级别的DeepSeek模型）、新兴应用范式（如Agents、MCP、A2A协议）及相关工具链。

平台设计重点关注环境隔离（使用Conda）、性能监控、多样化框架支持以及通过Tailscale实现的便捷远程访问。设备固定放置在办公室，主要通过MacBook远程连接工作，并支持偶尔的多用户访问需求。

## 2. 目标
### 2.1 业务目标
- 建立一个高性能、灵活的大模型实验平台，支持前沿AI研究和应用开发
- 提供一个稳定、可靠的环境，确保实验结果的一致性和可复现性
- 优化资源利用，最大化Apple Silicon M3 Ultra芯片的性能潜力
- 支持多种模型格式和框架，适应快速变化的AI技术生态
- 实现高效的远程工作流程，提升研究和开发效率

### 2.2 用户目标
- 能够轻松运行和测试各种规模的大型语言模型，包括超大规模模型（如671B DeepSeek）
- 在不同实验之间实现严格的环境隔离，避免依赖冲突
- 方便地监控系统资源使用情况，优化模型运行效率
- 能够从任何位置安全地远程访问实验平台
- 系统化地管理和追踪实验参数、指标和结果
- 高效地组织和管理多种模型文件，优化存储空间使用

### 2.3 非目标
- 不提供生产环境部署方案，仅专注于研究和实验
- 不支持大规模多用户并发访问，主要面向个人使用和有限的协作场景
- 不提供商业级别的高可用性保障
- 不针对非Apple Silicon架构优化
- 不提供完整的模型训练流程（主要关注推理、微调和应用开发）

## 3. 用户画像
### 3.1 关键用户类型
- 主要用户（平台所有者）
- 访客用户（偶尔访问测试的合作者）

### 3.2 基本画像细节
- **研究者**: 专注于大型语言模型研究的AI研究人员，需要灵活的环境来测试和评估各种模型和技术。
- **应用开发者**: 开发基于大型语言模型的应用的工程师，需要稳定的环境来构建和测试应用原型。
- **访客合作者**: 偶尔需要访问平台进行特定测试或演示的合作伙伴。

### 3.3 基于角色的访问
- **平台所有者**: 拥有完全访问权限，可以管理系统、安装软件、创建环境、运行任何实验。
- **访客用户**: 拥有受限访问权限，可以使用预先配置的环境运行特定实验，但不能修改系统配置或安装新软件。

## 4. 功能需求
- **环境隔离系统** (优先级: 高)
  - 使用Conda/Miniforge实现Python环境隔离
  - 为不同实验创建独立环境
  - 提供环境模板和自动化脚本
  - 可选的容器化支持（Docker/Podman）
  - 严格的环境文档化要求

- **多框架支持** (优先级: 高)
  - 支持Ollama快速部署和API访问
  - 支持Llama.cpp高效推理（特别是GGUF模型）
  - 支持Apple MLX原生框架
  - 支持PyTorch (MPS Backend)
  - 支持多种Agent框架（LangChain、LlamaIndex、AutoGen、CrewAI等）

- **模型管理系统** (优先级: 高)
  - 清晰的模型存储结构
  - 支持多种模型格式（GGUF、GPTQ、SafeTensors等）
  - 模型元数据管理
  - 量化工具支持
  - 优化存储空间使用（如符号链接）

- **资源监控系统** (优先级: 中)
  - 实时CPU/GPU/内存使用监控
  - 资源使用警报机制
  - 性能分析工具
  - 可视化监控仪表板

- **实验管理工具** (优先级: 中)
  - 实验参数和结果追踪
  - 实验版本控制
  - 可视化分析工具
  - 实验报告生成
  - 优先使用Weights & Biases，MLflow作为备选

- **远程访问系统** (优先级: 高)
  - 基于Tailscale的安全网络连接
  - SSH远程访问配置
  - 多设备支持
  - 连接故障排查机制

- **安全与备份** (优先级: 中)
  - 全盘加密
  - 定期系统更新
  - 自动备份重要数据
  - 访问控制机制
  - 定期维护计划

- **多用户支持** (优先级: 低)
  - 访客用户账户
  - 权限隔离
  - 预配置环境
  - 使用指南文档
  - API和Web界面分享机制

## 5. 用户体验
### 5.1. 入口点和首次用户流程
- 平台所有者通过Tailscale和SSH从MacBook远程连接到Mac Studio
- 首次连接时配置基本环境（Conda、监控工具、框架等）
- 创建初始实验环境和目录结构
- 设置模型存储系统和元数据管理

### 5.2. 核心体验
- **环境准备**: 用户为新实验创建专用Conda环境，安装所需依赖。
  - 使用预定义的环境模板或自动化脚本加速此过程。
- **模型获取与管理**: 用户下载或准备模型文件，放入适当的存储结构中。
  - 记录模型元数据，必要时进行量化处理。
- **实验执行**: 用户激活相应环境，运行实验代码，同时监控资源使用情况。
  - 使用asitop或htop实时监控系统资源，确保高效运行。
- **结果分析与管理**: 用户使用实验管理工具记录参数和结果，进行可视化分析。
  - 通过WandB或MLflow追踪实验全生命周期，确保可复现性。

### 5.3. 高级功能和边缘情况
- 运行超大规模模型（如671B DeepSeek）时的内存管理和优化
- 多用户同时访问时的资源分配和隔离
- 系统资源接近极限时的预警和自动保护机制
- 远程连接中断时的实验保护和恢复机制
- 存储空间不足时的自动清理和优化建议

### 5.4. UI/UX 亮点
- 资源监控仪表板，提供直观的系统状态可视化
- 实验管理界面，支持参数、结果的组织和比较
- 模型管理系统，支持元数据查询和筛选
- 自动化脚本库，简化常见操作
- 实验模板系统，加速新实验设置
- Vibe Coding工具（如Cursor）的rules文件，提供智能编码辅助

## 6. 叙述
李研是一位AI研究者，他需要一个强大而灵活的平台来探索最新的大型语言模型，包括超大规模的671B参数模型。他的Mac Studio M3 Ultra实验平台让他能够在办公室设置一个固定的高性能工作站，同时通过Tailscale从任何地点安全地远程访问。系统的环境隔离确保他的每个实验都不会相互干扰，而完善的监控和实验管理工具让他能够系统地追踪结果并优化性能，大大提高了他的研究效率和成果质量。

## 7. 成功指标
### 7.1. 以用户为中心的指标
- 实验设置时间减少50%（通过环境模板和自动化脚本）
- 远程访问成功率达到99%以上
- 实验环境冲突减少至接近零
- 用户能够成功运行各种规模的模型，包括超大规模模型
- 开发经验和最佳实践的文档化率达到95%以上

### 7.2. 业务指标
- 研究和开发周期缩短30%
- 实验可复现性提高至95%以上
- 资源利用率提高40%（通过更好的监控和优化）
- 成功支持至少5种不同的大模型框架和10种不同规模的模型

### 7.3. 技术指标
- 系统稳定性：平均无故障运行时间>30天
- 远程连接延迟<100ms
- 大模型（>70B参数）推理性能达到Apple Silicon理论性能的85%以上
- 存储空间利用效率提高50%（通过优化的存储结构和符号链接）

## 8. 技术考虑因素
### 8.1. 集成点
- Conda/Miniforge与各种Python框架的集成
- Tailscale与SSH的集成
- 监控工具与系统资源的集成
- 实验管理工具与版本控制系统的集成
- 量化工具与不同模型格式的集成

### 8.2. 数据存储和隐私
- 模型文件存储在本地和外接SSD，需要合理组织
- 实验数据可能存储在本地或云端（取决于选择的实验管理工具）
- 备份策略需考虑数据量大的特点
- 访客用户应只能访问指定数据
- 支持从多种渠道（Hugging Face、GitHub等）获取模型

### 8.3. 可扩展性和性能
- 系统应能随着模型规模增长而适应（通过量化和优化）
- 存储系统应支持扩展（通过外接存储）
- 性能优化应充分利用M3 Ultra的特性（如神经引擎）
- 内存使用需要精心管理，特别是对于超大模型
- 并发实验能力有限，需要合理调度

### 8.4. 潜在挑战
- Apple Silicon对某些AI框架的兼容性问题
- 超大模型（如671B）的内存和性能限制
- 远程访问的网络稳定性和安全性
- 多用户场景下的资源竞争
- 快速变化的AI生态对系统适应性的要求
- 严格文档管理的持续维护挑战

## 9. 里程碑和排序
### 9.1. 项目估算
- 中等：2-3周

### 9.2. 团队规模和构成
- 小型团队：总共1-2人
  - 1名主要实施者（平台所有者）
  - 可选的1名技术顾问（特定领域专家）

### 9.3. 建议阶段
- **阶段1**: 基础环境搭建（3-5天）
  - 安装操作系统和核心工具
  - 配置Conda环境管理系统
  - 安装监控工具
  - 设置Tailscale远程访问

- **阶段2**: 核心框架与模型管理（5-7天）
  - 安装和配置各种AI框架
  - 建立模型存储结构
  - 设置模型元数据管理系统
  - 测试基本模型运行

- **阶段3**: 实验工作流与高级功能（5-7天）
  - 配置实验管理工具
  - 创建自动化脚本库
  - 设置实验模板
  - 配置多用户支持
  - 实施安全与备份策略
  - 创建Vibe Coding工具rules文件

- **阶段4**: 测试与优化（3-5天）
  - 全面测试各种规模模型
  - 优化性能和资源使用
  - 测试远程访问和多用户场景
  - 文档完善和使用指南编写
  - 建立文档管理系统和知识库

## 10. 用户故事
### 10.1. 环境隔离与管理
- **ID**: US-001
- **描述**: 作为平台用户，我希望能够为每个实验创建独立的环境，以避免依赖冲突。
- **验收标准**:
  - 用户可以使用Conda轻松创建新环境
  - 环境之间的依赖完全隔离
  - 用户可以导出环境配置以便复现
  - 提供环境模板加速常见实验类型的设置

### 10.2. 运行大规模模型
- **ID**: US-002
- **描述**: 作为研究者，我希望能够运行超大规模模型（如671B DeepSeek），以进行前沿研究。
- **验收标准**:
  - 系统能够通过量化技术支持超大模型
  - 提供内存使用监控和优化建议
  - 模型加载和推理性能达到可接受水平
  - 提供不同量化级别的性能/质量权衡选项

### 10.3. 远程访问实验平台
- **ID**: US-003
- **描述**: 作为移动工作的用户，我希望能够从任何位置安全地访问实验平台。
- **验收标准**:
  - Tailscale配置成功，提供稳定的虚拟网络
  - SSH远程连接配置正确，支持密钥认证
  - 远程连接延迟低，体验流畅
  - 提供连接问题的故障排查指南

### 10.4. 模型管理与存储
- **ID**: US-004
- **描述**: 作为平台用户，我希望能够有效地管理和组织多种模型文件。
- **验收标准**:
  - 清晰的模型存储目录结构已实施
  - 支持模型元数据记录和查询
  - 存储空间使用优化（如通过符号链接）
  - 支持多种模型格式和量化版本

### 10.5. 资源监控与优化
- **ID**: US-005
- **描述**: 作为平台用户，我希望能够实时监控系统资源使用情况，以优化实验性能。
- **验收标准**:
  - asitop和htop工具正确安装和配置
  - 用户可以查看CPU、GPU、内存使用情况
  - 提供资源使用警报机制
  - 可选的资源监控仪表板可用

### 10.6. 实验管理与追踪
- **ID**: US-006
- **描述**: 作为研究者，我希望能够系统地管理和追踪实验参数、指标和结果。
- **验收标准**:
  - WandB或MLflow正确配置
  - 用户可以记录实验参数和结果
  - 支持实验比较和可视化
  - 实验数据可导出和共享

### 10.7. 多用户支持
- **ID**: US-007
- **描述**: 作为平台所有者，我希望能够安全地允许其他用户访问系统进行测试。
- **验收标准**:
  - 访客用户账户创建成功，权限受限
  - 为访客准备的预配置环境可用
  - 用户指南文档完整清晰
  - 访客活动可被监控和审计

### 10.8. 安全备份与恢复
- **ID**: US-008
- **描述**: 作为平台用户，我希望重要数据能够定期备份，以防意外丢失。
- **验收标准**:
  - 自动备份机制已配置
  - 备份包括关键配置和实验数据
  - 提供简单的数据恢复流程
  - 备份策略考虑了大文件（如模型）的特殊需求

### 10.9. 自动化工作流
- **ID**: US-009
- **描述**: 作为频繁进行实验的用户，我希望常见操作能够自动化，以提高效率。
- **验收标准**:
  - 自动化脚本库已创建
  - 脚本涵盖环境创建、模型下载与转换等常见操作
  - 脚本文档完整，使用方便
  - 用户可以轻松扩展脚本库
  - 脚本支持从多种渠道获取模型

### 10.10. 框架兼容性与测试
- **ID**: US-010
- **描述**: 作为多框架用户，我希望系统能够支持多种AI框架，并确保它们在Apple Silicon上正常工作。
- **验收标准**:
  - 所有列出的框架（Ollama、Llama.cpp、MLX、PyTorch等）安装成功
  - 每个框架的基本功能测试通过
  - 提供各框架在Apple Silicon上的优化建议
  - 框架间的互操作性问题已记录和解决

### 10.11. 文档管理系统
- **ID**: US-011
- **描述**: 作为平台用户，我希望有一个严谨详细的文档管理系统，以记录经验和最佳实践。
- **验收标准**:
  - 多层次文档结构已建立
  - 自动化文档生成机制已实施
  - 文档与代码版本控制同步
  - 实验记录标准化模板已创建
  - 知识库和最佳实践指南已建立

### 10.12. Vibe Coding工具支持
- **ID**: US-012
- **描述**: 作为使用Cursor等AI辅助编码工具的开发者，我希望有专门的rules文件来提高开发效率。
- **验收标准**:
  - Cursor rules文件已创建并包含项目特定指南
  - 编码标准、架构指南和最佳实践已文档化
  - 针对不同任务的特定规则集已定义
  - 自动化检查与提示机制已实施
  - rules文件与文档管理系统集成

# Mac Studio M3 Ultra 文档管理系统

## 1. 概述

本文档详细描述了Mac Studio M3 Ultra大模型实验平台的文档管理系统。严谨详细的文档管理是确保实验可复现性、知识积累和经验传承的关键。本系统旨在提供一个全面的框架，用于记录、组织和共享与平台相关的所有知识和经验。

## 2. 文档结构

### 2.1 多层次文档架构

文档管理系统采用分层结构，确保信息的组织性和可访问性：

1. **平台级文档**
   - `README.md` - 项目总体说明
   - `prd.md` - 产品需求文档
   - `architecture.md` - 系统架构概述
   - `setup_guide.md` - 初始设置指南
   - `maintenance.md` - 维护计划和指南

2. **环境级文档**
   - `/environments/README.md` - 环境管理概述
   - `/environments/{env_name}.md` - 每个环境的详细文档
   - `/environments/templates/` - 环境模板和最佳实践

3. **模型级文档**
   - `/models/README.md` - 模型管理概述
   - `/models/catalog.md` - 模型目录和元数据
   - `/models/{model_family}/` - 特定模型家族的文档

4. **实验级文档**
   - `/experiments/README.md` - 实验管理概述
   - `/experiments/{experiment_type}/` - 按实验类型组织的文档
   - `/experiments/templates/` - 实验模板和标准

5. **工具和脚本文档**
   - `/tools/README.md` - 工具概述
   - `/tools/{tool_name}.md` - 每个工具的详细文档
   - `/scripts/README.md` - 脚本库概述

6. **知识库**
   - `/knowledge_base/README.md` - 知识库概述
   - `/knowledge_base/troubleshooting.md` - 问题排查指南
   - `/knowledge_base/best_practices.md` - 最佳实践集合
   - `/knowledge_base/lessons_learned.md` - 经验教训记录

7. **Vibe Coding规则**
   - `/vibe_coding/README.md` - Vibe Coding概述
   - `/vibe_coding/cursor_rules.md` - Cursor规则文件
   - `/vibe_coding/code_snippets.md` - 代码片段库

## 3. 文档标准

### 3.1 文件命名约定

- 使用小写字母和下划线
- 文件名应简洁明了，反映内容
- 使用标准的文件扩展名（`.md`、`.yml`等）
- 示例：`model_loading_guide.md`、`experiment_template.yml`

### 3.2 文档格式标准

- 使用Markdown格式（GitHub Flavored Markdown）
- 每个文档应包含标题、日期、作者和版本信息
- 使用标准的标题层级（`#`、`##`、`###`等）
- 代码块应指定语言（如```python）
- 使用表格组织结构化数据
- 使用链接引用相关文档

### 3.3 文档模板

每类文档都有标准模板，确保一致性和完整性：

#### 实验文档模板
```markdown
# 实验：{实验名称}

## 元数据
- **ID**: {实验ID}
- **日期**: {YYYY-MM-DD}
- **作者**: {作者名}
- **环境**: {环境名称}
- **模型**: {使用的模型}
- **标签**: {相关标签}

## 目标
{实验目标的简明描述}

## 方法
{实验方法的详细描述}

## 设置
{环境设置、参数配置等}

```python
# 关键配置代码
```

## 结果
{实验结果的描述和分析}

## 结论
{从实验中得出的结论}

## 后续步骤
{建议的后续实验或改进}

## 参考
{相关文档、论文或资源的链接}
```

#### 模型文档模板
```markdown
# 模型：{模型名称}

## 元数据
- **名称**: {模型全名}
- **来源**: {Hugging Face/GitHub/其他}
- **URL**: {源URL}
- **参数量**: {参数数量}
- **格式**: {原始格式}
- **下载日期**: {YYYY-MM-DD}

## 描述
{模型的简要描述}

## 量化版本
- **4-bit**: {路径和性能特点}
- **8-bit**: {路径和性能特点}
- **GGUF**: {路径和性能特点}

## 性能特点
{在Mac Studio上的性能特点}

## 使用示例
```python
# 加载和使用模型的示例代码
```

## 注意事项
{使用此模型时的特殊考虑}

## 相关实验
{使用此模型的实验链接}
```

## 4. 自动化文档生成

### 4.1 环境文档自动生成

使用脚本自动从Conda环境生成文档：

```python
# 示例：环境文档生成脚本
import subprocess
import yaml
import os
from datetime import datetime

def generate_env_doc(env_name):
    """为指定的Conda环境生成文档"""
    # 获取环境信息
    result = subprocess.run(
        f"conda env export -n {env_name}",
        shell=True, capture_output=True, text=True
    )
    env_yaml = yaml.safe_load(result.stdout)
    
    # 生成文档
    doc = f"# 环境：{env_name}\n\n"
    doc += f"## 元数据\n"
    doc += f"- **创建日期**: {datetime.now().strftime('%Y-%m-%d')}\n"
    doc += f"- **Python版本**: {env_yaml['dependencies'][0].split('=')[1]}\n"
    doc += f"- **用途**: [填写环境用途]\n\n"
    
    doc += f"## 依赖包\n\n"
    doc += "### 核心包\n\n"
    doc += "| 包名 | 版本 | 用途 |\n"
    doc += "|------|------|------|\n"
    
    # 添加主要包信息
    for dep in env_yaml['dependencies']:
        if isinstance(dep, str) and not dep.startswith('python'):
            name = dep.split('=')[0]
            version = dep.split('=')[1] if '=' in dep else "latest"
            doc += f"| {name} | {version} | [填写用途] |\n"
    
    # 保存文档
    os.makedirs("environments", exist_ok=True)
    with open(f"environments/{env_name}.md", "w") as f:
        f.write(doc)
    
    print(f"环境文档已生成：environments/{env_name}.md")

# 使用示例
if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1:
        generate_env_doc(sys.argv[1])
    else:
        print("请提供环境名称")
```

### 4.2 实验记录自动化

使用Jupyter notebooks自动记录实验过程：

```python
# 在notebook开头添加的自动记录元数据的代码
import wandb
from datetime import datetime
import getpass
import socket
import sys
import platform
import torch
import os

# 记录实验元数据
experiment_metadata = {
    "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    "user": getpass.getuser(),
    "hostname": socket.gethostname(),
    "python_version": sys.version,
    "platform": platform.platform(),
    "torch_version": torch.__version__,
    "cuda_available": torch.cuda.is_available(),
    "gpu_info": torch.cuda.get_device_name(0) if torch.cuda.is_available() else "N/A",
    "experiment_name": "实验名称",  # 修改为实际实验名称
}

# 显示元数据
for key, value in experiment_metadata.items():
    print(f"{key}: {value}")

# 可选：初始化WandB
wandb.init(
    project="mac-studio-experiments",
    name=experiment_metadata["experiment_name"],
    config=experiment_metadata
)

# 实验结束时，导出notebook为markdown
def export_notebook_to_md():
    notebook_name = os.path.basename(globals()['_dh'][0])
    os.system(f"jupyter nbconvert --to markdown {notebook_name}.ipynb")
    print(f"Notebook已导出为markdown: {notebook_name}.md")
```

### 4.3 模型元数据自动化

使用脚本自动记录模型元数据：

```python
# 示例：模型元数据记录脚本
import json
import os
import argparse
from datetime import datetime
import hashlib

def calculate_file_hash(filepath):
    """计算文件的SHA256哈希值"""
    sha256_hash = hashlib.sha256()
    with open(filepath, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()

def record_model_metadata(model_path, model_name, source_url, model_type, description):
    """记录模型元数据"""
    # 获取文件信息
    file_size = os.path.getsize(model_path) / (1024 * 1024 * 1024)  # 转换为GB
    file_hash = calculate_file_hash(model_path)
    
    # 创建元数据
    metadata = {
        "name": model_name,
        "file_path": model_path,
        "file_size_gb": round(file_size, 2),
        "file_hash": file_hash,
        "source_url": source_url,
        "model_type": model_type,
        "description": description,
        "date_added": datetime.now().strftime("%Y-%m-%d"),
        "added_by": os.getenv("USER")
    }
    
    # 确保目录存在
    os.makedirs("models/metadata", exist_ok=True)
    
    # 保存元数据
    metadata_path = f"models/metadata/{model_name.replace('/', '_')}.json"
    with open(metadata_path, "w") as f:
        json.dump(metadata, f, indent=2)
    
    # 更新目录
    update_model_catalog(metadata)
    
    print(f"模型元数据已记录：{metadata_path}")

def update_model_catalog(metadata):
    """更新模型目录"""
    catalog_path = "models/catalog.md"
    
    # 如果目录不存在，创建它
    if not os.path.exists(catalog_path):
        with open(catalog_path, "w") as f:
            f.write("# 模型目录\n\n")
            f.write("| 模型名称 | 类型 | 大小(GB) | 添加日期 | 描述 |\n")
            f.write("|---------|------|----------|----------|------|\n")
    
    # 添加新模型到目录
    with open(catalog_path, "a") as f:
        f.write(f"| {metadata['name']} | {metadata['model_type']} | {metadata['file_size_gb']} | {metadata['date_added']} | {metadata['description']} |\n")

# 使用示例
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="记录模型元数据")
    parser.add_argument("--path", required=True, help="模型文件路径")
    parser.add_argument("--name", required=True, help="模型名称")
    parser.add_argument("--url", required=True, help="模型源URL")
    parser.add_argument("--type", required=True, help="模型类型")
    parser.add_argument("--desc", required=True, help="模型描述")
    
    args = parser.parse_args()
    record_model_metadata(args.path, args.name, args.url, args.type, args.desc)
```

## 5. 版本控制与同步

### 5.1 文档版本控制

- 所有文档都应纳入Git版本控制
- 文档更新应包含有意义的提交消息
- 重大更新应创建标签或发布版本
- 文档应与代码保持同步，使用相同的分支和标签

### 5.2 文档更新工作流

1. **检查**: 确认文档是否需要更新
2. **更新**: 修改相关文档
3. **审查**: 自我审查或请同事审查
4. **提交**: 提交更改，包含清晰的提交消息
5. **同步**: 确保文档与代码同步

### 5.3 文档审查清单

- [ ] 文档格式是否符合标准？
- [ ] 内容是否准确、最新？
- [ ] 是否包含所有必要信息？
- [ ] 链接是否有效？
- [ ] 是否有拼写或语法错误？
- [ ] 是否与相关文档保持一致？

## 6. 知识库管理

### 6.1 问题与解决方案记录

每当遇到并解决问题时，应记录到知识库中：

```markdown
## 问题: {简明问题描述}

### 症状
{详细描述问题的表现}

### 环境
- **系统**: macOS {版本}
- **硬件**: Mac Studio M3 Ultra
- **相关软件**: {软件名称和版本}

### 原因
{问题的根本原因分析}

### 解决方案
{详细的解决步骤}

```bash
# 如果适用，包含相关命令
```

### 注意事项
{使用此解决方案时的注意事项}

### 参考
{相关资源链接}
```

### 6.2 最佳实践收集

持续收集和更新最佳实践：

```markdown
## 最佳实践: {实践名称}

### 适用场景
{描述此最佳实践适用的场景}

### 实践详情
{详细描述最佳实践}

### 示例
```python
# 示例代码
```

### 好处
{采用此实践的好处}

### 注意事项
{实施此实践时的注意事项}
```

### 6.3 经验教训记录

记录项目中的经验教训：

```markdown
## 经验教训: {简明描述}

### 背景
{提供背景信息}

### 事件
{描述发生的事件}

### 影响
{事件的影响}

### 学到的教训
{从事件中学到的教训}

### 改进建议
{如何避免类似问题或改进流程}
```

## 7. 文档维护

### 7.1 定期审查

- 每月审查一次核心文档
- 每季度审查一次所有文档
- 使用审查清单确保质量

### 7.2 文档健康检查

定期运行脚本检查文档健康状况：

```python
# 示例：文档健康检查脚本
import os
import re
import datetime

def check_docs_health(docs_dir):
    """检查文档健康状况"""
    issues = []
    
    # 遍历所有markdown文件
    for root, _, files in os.walk(docs_dir):
        for file in files:
            if file.endswith(".md"):
                filepath = os.path.join(root, file)
                
                # 检查文件
                with open(filepath, "r") as f:
                    content = f.read()
                    
                    # 检查标题
                    if not re.search(r'^# ', content, re.MULTILINE):
                        issues.append(f"{filepath}: 缺少主标题")
                    
                    # 检查日期
                    if not re.search(r'\d{4}-\d{2}-\d{2}', content):
                        issues.append(f"{filepath}: 可能缺少日期")
                    
                    # 检查空链接
                    if re.search(r'\[\]\(\)', content):
                        issues.append(f"{filepath}: 包含空链接")
                    
                    # 检查TODO标记
                    todos = re.findall(r'TODO', content)
                    if todos:
                        issues.append(f"{filepath}: 包含{len(todos)}个TODO标记")
    
    # 生成报告
    report = f"# 文档健康检查报告\n\n"
    report += f"**日期:** {datetime.datetime.now().strftime('%Y-%m-%d')}\n\n"
    
    if issues:
        report += "## 发现的问题\n\n"
        for issue in issues:
            report += f"- {issue}\n"
    else:
        report += "**恭喜!** 未发现文档问题。\n"
    
    # 保存报告
    with open("doc_health_report.md", "w") as f:
        f.write(report)
    
    print(f"文档健康检查完成，发现{len(issues)}个问题。详情请查看doc_health_report.md")

# 使用示例
if __name__ == "__main__":
    check_docs_health(".")
```

### 7.3 文档更新日志

维护一个文档更新日志，记录重要变更：

```markdown
# 文档更新日志

## [2023-12-01]
### 添加
- 添加了模型管理指南
- 添加了实验模板

### 修改
- 更新了环境设置指南
- 改进了故障排查文档

### 修复
- 修复了安装指南中的错误链接
```

## 8. 与Vibe Coding工具集成

### 8.1 Cursor Rules文件与文档同步

确保Cursor Rules文件与文档系统保持同步：

- Rules文件应引用相关文档
- 文档应包含Rules文件的相关部分
- 更新Rules文件时同时更新相关文档

### 8.2 自动化文档生成与Vibe Coding

使用Vibe Coding工具辅助文档生成：

- 使用Cursor生成文档模板
- 使用AI辅助完善文档内容
- 使用Rules文件确保文档风格一致

## 9. 实施计划

### 9.1 初始设置

1. 创建文档目录结构
2. 设置文档模板
3. 初始化Git仓库
4. 创建初始README和指南

### 9.2 持续维护

1. 每次实验后更新相关文档
2. 每周整理和组织新增知识
3. 每月审查文档健康状况
4. 每季度进行全面文档审查

## 10. 结论

严谨详细的文档管理是Mac Studio M3 Ultra大模型实验平台成功的关键。通过实施本文档管理系统，我们可以确保知识的积累、经验的传承和实验的可复现性，从而最大化平台的价值和效率。

# Mac Studio M3 Ultra - Vibe Coding Rules

## 1. 概述

本文档定义了Mac Studio M3 Ultra大模型实验平台的Vibe Coding规则，专为Cursor等AI辅助编码工具设计。这些规则提供了关键原则和模式，详细实现请参考相应的文档。

> **重要提示**: 本文档不包含所有细节，而是提供关键指导并引导您查看相关详细文档。

## 2. 文档引用指南

根据不同任务，请参考以下文档：

- **环境管理**: 查看 `documentation_system.md` 中的"环境级文档"部分
- **模型处理**: 查看 `models/README.md` 获取模型管理最佳实践
- **实验设计**: 查看 `experiments/README.md` 了解实验设计和执行标准
- **性能优化**: 查看 `knowledge_base/performance.md` 获取Apple Silicon优化技巧
- **故障排除**: 查看 `knowledge_base/troubleshooting.md` 获取常见问题解决方案

## 3. 核心编码原则

### 3.1 命名约定

- **文件名**: 小写字母和下划线分隔 (例如: `model_loader.py`)
- **类名**: 驼峰命名法 (例如: `ModelManager`)
- **函数和变量**: 小写字母和下划线分隔 (例如: `load_model()`)
- **常量**: 全大写字母和下划线分隔 (例如: `MAX_BATCH_SIZE`)
- **环境名**: 描述性名称和下划线分隔 (例如: `llama2_70b_rag`)

### 3.2 导入顺序

```python
# 标准库导入
import os
import sys

# 第三方库导入
import torch
import numpy as np

# 本地模块导入
from utils.logging import setup_logger
```

### 3.3 文档要求

每个模块、类和函数必须有文档字符串，包括:
- 简要描述
- 参数说明
- 返回值说明
- 异常说明（如适用）

详细标准请参考 `documentation_system.md`。

## 4. 关键模式和最佳实践

### 4.1 环境管理

```python
# 创建新环境时使用此模式
conda create -n {env_name} python=3.10 -y
conda activate {env_name}
pip install {packages}
conda env export > environment_{env_name}.yml
```

每个环境创建后必须记录在文档中。详细请参考环境管理文档。

### 4.2 模型加载

```python
# 模型加载的标准模式
try:
    # 设置适当的量化参数
    load_kwargs = {"device_map": "mps"}
    if model_size > 13:  # 大于13B的模型
        load_kwargs.update({"load_in_4bit": True})

    # 加载模型
    model = AutoModelForCausalLM.from_pretrained(model_path, **load_kwargs)
    tokenizer = AutoTokenizer.from_pretrained(model_path)

    return model, tokenizer
except Exception as e:
    logger.error(f"模型加载失败: {str(e)}")
    raise
```

对于超大模型（如671B DeepSeek），请参考 `models/large_models.md` 获取特殊处理指南。

### 4.3 实验执行

```python
# 实验执行的标准模式
def run_experiment(config_path):
    # 1. 加载配置
    config = load_config(config_path)

    # 2. 设置随机种子确保可复现性
    set_seed(config.get("seed", 42))

    # 3. 初始化实验跟踪
    wandb.init(project=config["project_name"], config=config)

    # 4. 执行实验逻辑
    # ...

    # 5. 记录结果
    wandb.log({"metric": value})
```

详细的实验设计和执行标准请参考实验文档。

## 5. Apple Silicon 优化

- 优先使用 MPS 后端而非 CPU
- 对于大型模型，使用4-bit或8-bit量化
- 监控内存使用，避免OOM错误
- 考虑使用MLX框架获得更好的性能

详细优化技巧请参考性能优化文档。

## 6. 常见问题与解决方案

当遇到以下问题时，请参考相应文档：

- **内存不足**: 参考 `knowledge_base/memory_management.md`
- **模型加载失败**: 参考 `knowledge_base/model_loading.md`
- **MPS后端问题**: 参考 `knowledge_base/mps_issues.md`
- **远程连接问题**: 参考 `knowledge_base/remote_access.md`

## 7. Vibe Coding工具调用技巧

### 7.1 分块修改策略

在使用Cursor等AI辅助编码工具时，大量的读写调用容易失败。要提高成功率，请遵循以下原则：

- **小批量修改**: 每次修改不超过200行代码
- **分步操作**: 将大型文件修改分解为多个小步骤
- **逐步确认**: 每次修改后确认变更已成功应用
- **增量修改**: 优先使用增量修改而非全文件替换

示例工作流程：

1. 首先查看文件当前状态
2. 确定要修改的特定部分（不超过200行）
3. 只修改该部分，保持其他部分不变
4. 确认修改成功后再进行下一部分

### 7.2 读写工具调用模式

#### 7.2.1 文件读取

```python
# 推荐模式：安全读取文件
def read_file(file_path):
    """安全地读取文件"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        logger.error(f"文件不存在: {file_path}")
        return None
    except Exception as e:
        logger.error(f"读取文件失败: {str(e)}")
        return None
```

#### 7.2.2 文件写入

```python
# 推荐模式：安全写入文件
def write_file(file_path, content, mode='w'):
    """安全地写入文件"""
    # 创建目录（如果不存在）
    os.makedirs(os.path.dirname(file_path), exist_ok=True)

    try:
        with open(file_path, mode, encoding='utf-8') as f:
            f.write(content)
        return True
    except Exception as e:
        logger.error(f"写入文件失败: {str(e)}")
        return False
```

#### 7.2.3 JSON数据处理

```python
# 推荐模式：JSON数据读写
import json

def load_json(file_path):
    """加载JSON文件"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"加载JSON失败: {str(e)}")
        return None

def save_json(file_path, data, indent=2):
    """保存JSON文件"""
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=indent)
        return True
    except Exception as e:
        logger.error(f"保存JSON失败: {str(e)}")
        return False
```

#### 7.2.4 数据流处理

处理大型文件或数据流时，使用迭代器和生成器：

```python
# 推荐模式：处理大型文件
def process_large_file(file_path, chunk_size=1024*1024):
    """分块处理大型文件"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            while True:
                chunk = f.read(chunk_size)
                if not chunk:
                    break
                # 处理数据块
                process_chunk(chunk)
        return True
    except Exception as e:
        logger.error(f"处理文件失败: {str(e)}")
        return False
```

#### 7.2.5 并发读写

当需要并发处理多个文件时：

```python
# 推荐模式：并发文件处理
from concurrent.futures import ThreadPoolExecutor

def process_files_concurrently(file_paths, process_func, max_workers=4):
    """并发处理多个文件"""
    import concurrent.futures
    results = {}
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_file = {executor.submit(process_func, file_path): file_path
                          for file_path in file_paths}
        for future in concurrent.futures.as_completed(future_to_file):
            file_path = future_to_file[future]
            try:
                results[file_path] = future.result()
            except Exception as e:
                logger.error(f"处理文件 {file_path} 失败: {str(e)}")
                results[file_path] = None
    return results
```

有关读写工具的更多技巧和最佳实践，请参考 `knowledge_base/io_operations.md`。

## 8. 文档维护

- 发现新的最佳实践时，更新相关文档
- 遇到并解决新问题时，添加到知识库
- 定期审查和更新文档

详细的文档维护流程请参考文档管理系统文档。
